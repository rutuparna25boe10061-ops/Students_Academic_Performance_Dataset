{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. Data Preprocessing & Engineering Module (Functional Module 1) ---\n",
        "\n",
        "def preprocess_data(file_path):\n",
        "    \"\"\"\n",
        "    Loads data, engineers the target variable, and prepares features for ML.\n",
        "    \"\"\"\n",
        "    print(\"--- 1. Starting Data Preprocessing & Feature Engineering ---\")\n",
        "\n",
        "    # 1.1 Load Dataset\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # Clean column names by removing spaces and slashes\n",
        "    df.columns = df.columns.str.replace(' ', '_').str.replace('/', '_')\n",
        "\n",
        "    # 1.2 Feature Engineering: Create the Target Variable ('Performance_Level')\n",
        "    # Calculate the average score for each student\n",
        "    df['average_score'] = df[['math_score', 'reading_score', 'writing_score']].mean(axis=1)\n",
        "\n",
        "    # Define a binary classification target:\n",
        "    # 1 for 'High Performer' (average score >= 70), 0 for 'Low Performer'\n",
        "    # The threshold can be adjusted, but 70 is a reasonable initial choice for \"Success\"\n",
        "    performance_threshold = 70\n",
        "    df['Performance_Level'] = (df['average_score'] >= performance_threshold).astype(int)\n",
        "\n",
        "    print(f\"Target variable created: 'Performance_Level' (1=Success, 0=Failure, Threshold: {performance_threshold})\")\n",
        "    print(f\"Success count: {df['Performance_Level'].sum()} / {len(df)}\")\n",
        "\n",
        "    # Define features (X) and target (y)\n",
        "    # Drop the original scores and the engineered average score to avoid data leakage\n",
        "    X = df.drop(columns=['math_score', 'reading_score', 'writing_score', 'average_score', 'Performance_Level'])\n",
        "    y = df['Performance_Level']\n",
        "\n",
        "    # 1.3 Identify Feature Types\n",
        "    categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # 1.4 Create a Column Transformer for One-Hot Encoding\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "        ],\n",
        "        remainder='passthrough' # Keep other columns (none in this case, but good practice)\n",
        "    )\n",
        "\n",
        "    # 1.5 Split Data into Training and Testing Sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"Data split: Training samples={len(X_train)}, Testing samples={len(X_test)}\")\n",
        "    print(\"--- Data Preprocessing Complete ---\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, preprocessor\n",
        "\n",
        "# --- 2. Model Training & Tuning Module (Functional Module 2) ---\n",
        "\n",
        "def train_and_tune_model(X_train, y_train, preprocessor):\n",
        "    \"\"\"\n",
        "    Builds a pipeline, performs hyperparameter tuning, and trains the final model.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- 2. Starting Model Training & Tuning ---\")\n",
        "\n",
        "    # 2.1 Define the Model Pipeline\n",
        "    # The pipeline combines the preprocessor (OHE) and the classifier\n",
        "    model_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', RandomForestClassifier(random_state=42)) # Using Random Forest Classifier\n",
        "    ])\n",
        "\n",
        "    # 2.2 Hyperparameter Tuning with GridSearchCV\n",
        "    # Define a grid of hyperparameters to search\n",
        "    param_grid = {\n",
        "        'classifier__n_estimators': [100, 200],  # Number of trees\n",
        "        'classifier__max_depth': [5, 10, None],  # Max depth of trees\n",
        "        'classifier__min_samples_split': [2, 5]  # Minimum number of samples required to split an internal node\n",
        "    }\n",
        "\n",
        "    # Use Grid Search for systematic hyperparameter optimization\n",
        "    grid_search = GridSearchCV(\n",
        "        model_pipeline,\n",
        "        param_grid,\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Fit the grid search to the training data\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # The best estimator from the search is our final trained model\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    print(\"\\nBest parameters found by Grid Search:\")\n",
        "    print(grid_search.best_params_)\n",
        "\n",
        "    print(\"\\n--- Model Training & Tuning Complete ---\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# --- 3. Prediction & Reporting Interface Module (Functional Module 3) ---\n",
        "\n",
        "def evaluate_model(best_model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the test set and prints a detailed report.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- 3. Starting Model Evaluation & Reporting ---\")\n",
        "\n",
        "    # 3.1 Make predictions on the test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # 3.2 Calculate and print evaluation metrics\n",
        "    print(\"\\nModel Evaluation on Test Data:\")\n",
        "    print(\"-----------------------------------\")\n",
        "\n",
        "    # Accuracy Score\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Classification Report (Precision, Recall, F1-Score)\n",
        "    print(\"\\nClassification Report (0=Low Performer, 1=High Performer):\\n\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Low Performer', 'High Performer']))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_mat)\n",
        "    #\n",
        "    print(\"--- Model Evaluation Complete ---\")\n",
        "\n",
        "    return conf_mat, test_accuracy\n",
        "\n",
        "def save_model(model, filename=\"final_ml_model.pkl\"):\n",
        "    \"\"\"\n",
        "    Saves the trained model to a file using pickle.\n",
        "    \"\"\"\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(model, file)\n",
        "    print(f\"\\n✅ Trained model saved as {filename}\")\n",
        "\n",
        "def predict_new_student(model, new_data):\n",
        "    \"\"\"\n",
        "    Function to demonstrate prediction on new, unseen student data.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Prediction Demonstration ---\")\n",
        "    # Convert the new data to a DataFrame, matching the training features\n",
        "    new_df = pd.DataFrame([new_data])\n",
        "\n",
        "    # Make the prediction\n",
        "    prediction = model.predict(new_df)\n",
        "\n",
        "    performance_map = {1: \"High Performer (SUCCESS)\", 0: \"Low Performer (FAILURE)\"}\n",
        "    result = performance_map[prediction[0]]\n",
        "\n",
        "    print(f\"Input Student Data:\\n{new_df.iloc[0].to_dict()}\")\n",
        "    print(f\"\\nPredicted Performance Level: {result}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    DATA_FILE = 'StudentsPerformance.csv' #\n",
        "    MODEL_OUTPUT_FILE = 'student_performance_classifier.pkl'\n",
        "\n",
        "    # 1. Data Preprocessing\n",
        "    X_train, X_test, y_train, y_test, preprocessor = preprocess_data(DATA_FILE)\n",
        "\n",
        "    if X_train is not None:\n",
        "        # 2. Model Training & Tuning\n",
        "        trained_model = train_and_tune_model(X_train, y_train, preprocessor)\n",
        "\n",
        "        # Save the final model\n",
        "        save_model(trained_model, MODEL_OUTPUT_FILE)\n",
        "\n",
        "        # 3. Model Evaluation and Reporting\n",
        "        evaluate_model(trained_model, X_test, y_test)\n",
        "\n",
        "        # Demonstrate prediction on a new data point\n",
        "        sample_new_student = {\n",
        "            'gender': 'female',\n",
        "            'race_ethnicity': 'group D', # Changed from 'race/ethnicity'\n",
        "            'parental_level_of_education': \"bachelor's degree\", # Changed from 'parental level of education'\n",
        "            'lunch': 'standard',\n",
        "            'test_preparation_course': 'completed' # Changed from 'test preparation course'\n",
        "        }\n",
        "        predict_new_student(trained_model, sample_new_student)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0dxB3IJ14ER",
        "outputId": "155701a6-e10e-44e6-e5da-c5badfd4f1e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Starting Data Preprocessing & Feature Engineering ---\n",
            "Target variable created: 'Performance_Level' (1=Success, 0=Failure, Threshold: 70)\n",
            "Success count: 459 / 1000\n",
            "Data split: Training samples=800, Testing samples=200\n",
            "--- Data Preprocessing Complete ---\n",
            "\n",
            "--- 2. Starting Model Training & Tuning ---\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "\n",
            "Best parameters found by Grid Search:\n",
            "{'classifier__max_depth': 5, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
            "\n",
            "--- Model Training & Tuning Complete ---\n",
            "\n",
            "✅ Trained model saved as student_performance_classifier.pkl\n",
            "\n",
            "--- 3. Starting Model Evaluation & Reporting ---\n",
            "\n",
            "Model Evaluation on Test Data:\n",
            "-----------------------------------\n",
            "Accuracy: 0.6250\n",
            "\n",
            "Classification Report (0=Low Performer, 1=High Performer):\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            " Low Performer       0.63      0.74      0.68       108\n",
            "High Performer       0.62      0.49      0.55        92\n",
            "\n",
            "      accuracy                           0.62       200\n",
            "     macro avg       0.62      0.61      0.61       200\n",
            "  weighted avg       0.62      0.62      0.62       200\n",
            "\n",
            "Confusion Matrix:\n",
            "[[80 28]\n",
            " [47 45]]\n",
            "--- Model Evaluation Complete ---\n",
            "\n",
            "--- Prediction Demonstration ---\n",
            "Input Student Data:\n",
            "{'gender': 'female', 'race_ethnicity': 'group D', 'parental_level_of_education': \"bachelor's degree\", 'lunch': 'standard', 'test_preparation_course': 'completed'}\n",
            "\n",
            "Predicted Performance Level: High Performer (SUCCESS)\n"
          ]
        }
      ]
    }
  ]
}